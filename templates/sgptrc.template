# Shell-GPT Configuration Template
# Provider: OpenAI (default)
# Generated for sgpt-wrapper project

# =============================================================================
# API CONFIGURATION
# =============================================================================

# OpenAI API configuration (DEFAULT)
OPENAI_API_KEY=YOUR_OPENAI_API_KEY
OPENAI_API_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4
OPENAI_ORG_ID=

# MiniMax API configuration
MINIMAX_API_KEY=YOUR_MINIMAX_API_KEY
MINIMAX_API_BASE_URL=https://api.minimax.io/v1
MINIMAX_MODEL=MiniMax-M2.1

# Ollama API configuration (local)
OLLAMA_API_KEY=not_needed_for_local
OLLAMA_API_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama2

# Together AI API configuration
TOGETHER_API_KEY=YOUR_TOGETHER_API_KEY
TOGETHER_API_BASE_URL=https://api.together.ai/v1
TOGETHER_MODEL=meta-llama/Llama-2-70b-chat-hf

# Groq API configuration
GROQ_API_KEY=YOUR_GROQ_API_KEY
GROQ_API_BASE_URL=https://api.groq.com/openai/v1
GROQ_MODEL=llama2-70b-8192

# =============================================================================
# WRAPPER-SPECIFIC SETTINGS
# =============================================================================

# Default provider (uncomment one):
# DEFAULT_PROVIDER=openai
DEFAULT_PROVIDER=minimax
# DEFAULT_PROVIDER=ollama
# DEFAULT_PROVIDER=together
# DEFAULT_PROVIDER=groq

# Wrapper-specific system prompt
WRAPPER_SYSTEM_PROMPT=You are a helpful AI assistant.

# Default model for the wrapper
WRAPPER_MODEL=MiniMax-M2.1

# =============================================================================
# GENERAL SETTINGS
# =============================================================================

# Cache settings
CACHE_ENABLED=true
CACHE_PATH=~/.cache/shell_gpt

# Display settings
SHOW_PROVIDER=true
SHOW_MODEL=true

# Edit behavior
EDITOR=nano
